schema: '2.0'
stages:
  train_tokenizer:
    cmd: python train_tokenizer.py --tokenizer-out .data/wmt20.bpetokenizer --dataset
      wmt20_mlqe_task1 --languages ru-en
    deps:
    - path: train_tokenizer.py
      md5: f744e0d25ea1b92a4457d49bdea19fc4
      size: 1334
    outs:
    - path: .data/wmt20.bpetokenizer
      md5: e19dfb66cba6fd209f59ea9dccf70214
      size: 898442
  echo_bert_inv_tokens:
    cmd: python train_bert.py --name echo_bert_inv_tokens --tokenizer .data/wmt20.bpetokenizer
      --dataset wmt20_mlqe_task1 --languages ru-en --batch_size 10 --noam_opt_warmup_steps
      1000 --gpus 1 --limit_val_batches=15 --max_epochs 15 --early_stopping_patience
      1000 --noam_scaler=0.3 --emb_norm_reg 0.0001
    deps:
    - path: .data/wmt20.bpetokenizer
      md5: e19dfb66cba6fd209f59ea9dccf70214
      size: 898442
    - path: train_bert.py
      md5: 5ee275616e9936b5b8ce9949d86537a9
      size: 13414
    - path: train_tokenizer.py
      md5: f744e0d25ea1b92a4457d49bdea19fc4
      size: 1334
    outs:
    - path: lightning_logs/echo_bert_inv_tokens
      md5: 5b0f0528d2f4732454c285080c3e8dbc.dir
      size: 113043107
      nfiles: 3
